# Maths Gradient Descent

Projet de TP visant à étudier la descente de gradient et ses variantes.


- Comprendre le principe de la descente de gradient
- Implémenter plusieurs algorithmes d’optimisation : Descente de gradient classique, Momentum, Nesterov, Adam
- Tester ces algorithmes sur différentes fonctions
- Visualiser les trajectoires et comparer les performances

Structure du projet
- `src/` : implémentations des fonctions, gradients et optimiseurs
- `notebooks/` : tests et explorations
- `figures/` : images générées pour le rapport
- `rapport/` : rapport final

Exécution
Les figures peuvent être générées via les notebooks ou les scripts Python.
